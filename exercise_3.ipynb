{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA20001 Deep Learning 2018 - Exercise 3\n",
    "\n",
    "**Due Sunday November 25, before 23:59**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.1 (2 points)\n",
    "\n",
    "Perform convolution on the given image with three different $3\\times 3$ kernels: a) blurring kernel, b) edge detection kernel, and c) your own kernel (you can make anything up, and try to explain what it does to the image).  2D convolution is defined as:\n",
    "\n",
    "$$S(i,j) = \\sum_m \\sum_n I(i+m, j+n) K(m,n),$$\n",
    "\n",
    "where $I$ is the image and $K$ is the kernel. The sums are taken over the kernel's dimensions: in this case $m=-1, 0, 1$ and $n = -1, 0, 1$ to get the kernel centered.\n",
    "\n",
    "See slides 19 and 20 in from [Lecture 5](https://moodle.helsinki.fi/pluginfile.php/2184375/mod_resource/content/2/lecture5.pdf) for how the results should roughly look like.  Don't worry if they are not exactly the same.  Especially for the edge detection, the picture in the slides has been processed by taking the absolute value and a threshold.\n",
    "\n",
    "Don't use PyTorch or any ready-made convolution function, instead implement the convolution by hand with numpy. No neural networks needed, just perform the convolution as the formula says. Perform what is called \"valid\" padding. Use a stride of 1. <span style=\"background-color: yellow\">Please return the code and one image for each of the three kernels showing the result of applying that kernel to the given image</span>.\n",
    "\n",
    "Below is some code to load the image, and to specify the kernels for a) and b) cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "I = plt.imread('images/doge.png')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(I, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blurring kernel\n",
    "K_blur = np.ones((3,3))/9.0\n",
    "print(K_blur)\n",
    "\n",
    "# Edge detection\n",
    "K_edge = np.array([[0, 1, 0],\n",
    "                   [1, -4, 1],\n",
    "                   [0, 1, 0]])\n",
    "print(K_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.2 (4 points)\n",
    "\n",
    "The task is to classify images of items of clothing from the FashionMNIST dataset using CNNs.  This is the same as in Exercise 2.2, except with CNN instead of MLP.\n",
    "\n",
    "<span style=\"background-color: yellow\">The task is to train a CNN model, i.e., a neural network with convolutional layers to classify images into the ten classes</span>.  You should train on the training set loaded below, and you should use the validation set to calculate the accuracy of the model (i.e., the percentage of correctly classified images of the validation set).\n",
    "\n",
    "Your network should have at least one convolutional layer, and at least one fully connected layer (you need one to get the final output anyway).  <span style=\"background-color: yellow\">In addition you should</span>:\n",
    "\n",
    "1. Try different setups, e.g., varying the number of layers, the sizes of kernels, strides, pooling, etc, and comment on what worked and what not.\n",
    "2. Play with the training parameters, e.g., what optimizer to use or minibatch sizes, and report the differences.\n",
    "3. Try **at least two** of the following methods mentioned in lecture 6 and <span style=\"background-color: yellow\">report what improvement to the accuracy (if any) you could achieve with these</span>:\n",
    "  - dataset augmentation, e.g., random crops or flips - Hint: you can add them as transforms to the dataset (see https://pytorch.org/docs/stable/torchvision/transforms.html)\n",
    "\n",
    "  - batch normalization\n",
    "\n",
    "  - dropout for fully connected layers.\n",
    "4. Visualise the weights of the first convolutional layer, can the weights be interpreted somehow?\n",
    "\n",
    "*Hint:* you can reuse most of the training and validation code from Exercise 2.2, or the PyTorch tutorial from lecture 4, just redefine the `Net` class.\n",
    "\n",
    "Below are some commands to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Let's load the dataset, fortunately FashionMNIST is also available directly in torchvision\n",
    "batch_size = 32\n",
    "train_dataset = datasets.FashionMNIST('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "validation_dataset = datasets.FashionMNIST('./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('Using GPU!')\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print('Using CPU')\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
